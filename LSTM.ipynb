{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhinash200301/Continuous-Time-Networks-for-Adaptive-Process-Control/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Setups"
      ],
      "metadata": {
        "id": "79soaii8iRvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.13.0\n",
        "!pip install keras==2.13.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGNAFHs-g1nN",
        "outputId": "319b06d4-ab0c-412e-94bb-32692e418b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.13.0 in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.12.1)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.24.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n",
            "Requirement already satisfied: keras==2.13.1 in /usr/local/lib/python3.10/dist-packages (2.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA3apAmyfo0r",
        "outputId": "a7f361df-cfbb-4f9a-d32a-b6848336a664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.1)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (2.13.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylFg6ScZhtsC"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow_addons.metrics import RSquare\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(\"/content/PostDischarge_Data.csv\")"
      ],
      "metadata": {
        "id": "JcHei9s3XB-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label=df[\"label\"]\n",
        "ct=[]\n",
        "for i in np.unique(label):\n",
        "  count=0\n",
        "  for j in range(len(df)):\n",
        "    if df[\"label\"][j]== i:\n",
        "      count=count+1\n",
        "  ct.append(count)"
      ],
      "metadata": {
        "id": "Lr2BHEG0cfOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m=np.unique(label)"
      ],
      "metadata": {
        "id": "9CcdXecU4k_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l=0\n",
        "for i in range(len(ct)):\n",
        "  df1= df[l:l+ct[i]]\n",
        "  with pd.ExcelWriter(m[i]+\".xlsx\") as writer:\n",
        "    df1.to_excel(writer)\n",
        "  l= ct[i]+l\n",
        "  print(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE4exGOQ_zyB",
        "outputId": "8c6febbd-3289-4bb6-a581-9ebe7b43d7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "349\n",
            "529\n",
            "730\n",
            "764\n",
            "1092\n",
            "1304\n",
            "1444\n",
            "1480\n",
            "1805\n",
            "2122\n",
            "2420\n",
            "2729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 5  # Length of the input sequence"
      ],
      "metadata": {
        "id": "tHwi7Jm_fbyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of Excel files\n",
        "a = glob.glob(\"*.xlsx\")\n",
        "\n",
        "# Lists to store inputs and outputs\n",
        "train_input = []\n",
        "train_output = []\n",
        "\n",
        "# Loop through each file\n",
        "for j in a:\n",
        "    dfk = pd.read_excel(j)\n",
        "    dfm = dfk.drop(columns=['label', 'cycle number', 'Unnamed: 0'])  # Drop unnecessary columns\n",
        "\n",
        "    # Loop to create sequences based on the specified sequence length\n",
        "    for i in range(len(dfk) - sequence_length):\n",
        "        ink = []\n",
        "        # Collecting the previous 'sequence_length' steps\n",
        "        for n in range(sequence_length):\n",
        "            ink.append(list(dfm[i + n:i + n + 1].values[0]))\n",
        "        train_input.append(ink)\n",
        "\n",
        "        # Predict the next value after the sequence\n",
        "        train_output.append(list(dfm[i + sequence_length:i + sequence_length + 1].values[0])[0])"
      ],
      "metadata": {
        "id": "8ogXU1v7fbve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert lists to numpy arrays\n",
        "train_input = np.array(train_input)\n",
        "train_output = np.array(train_output)"
      ],
      "metadata": {
        "id": "ICbGeG_ofbst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure train_output is reshaped to (samples, 1)\n",
        "train_output = train_output.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "k1KzHI_oDfrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (sequence_length, 121)"
      ],
      "metadata": {
        "id": "G6DjgsdCne0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(input_shape):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=input_shape))\n",
        "    model.add(layers.LSTM(100, activation='relu', return_sequences=False))\n",
        "    model.add(layers.Dense(64, activation=\"relu\"))\n",
        "    model.add(layers.Dense(1, activation=\"linear\"))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[RSquare()])\n",
        "    return model\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = get_model(input_shape)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "6YMVvu1sm1Ul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "658d47b4-9fad-439c-8e39-7f04283e2b20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 100)               88800     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                6464      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 95329 (372.38 KB)\n",
            "Trainable params: 95329 (372.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "9MAIkcxkpvlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_input, train_output, epochs=150, validation_split=0.1, verbose=1)"
      ],
      "metadata": {
        "id": "GvUujlDKm1Tu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2600b0e6-0fc0-4dcb-fa74-adda43a9363a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "76/76 [==============================] - 4s 15ms/step - loss: 137.3932 - r_square: -3.7892 - val_loss: 1.7659 - val_r_square: 0.7366\n",
            "Epoch 2/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.3032 - r_square: 0.9894 - val_loss: 0.9893 - val_r_square: 0.8525\n",
            "Epoch 3/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.2262 - r_square: 0.9921 - val_loss: 0.9887 - val_r_square: 0.8525\n",
            "Epoch 4/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.2296 - r_square: 0.9920 - val_loss: 0.9754 - val_r_square: 0.8545\n",
            "Epoch 5/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.2247 - r_square: 0.9922 - val_loss: 0.9913 - val_r_square: 0.8522\n",
            "Epoch 6/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.1832 - r_square: 0.9936 - val_loss: 1.2020 - val_r_square: 0.8207\n",
            "Epoch 7/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.1967 - r_square: 0.9931 - val_loss: 0.9861 - val_r_square: 0.8529\n",
            "Epoch 8/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1724 - r_square: 0.9940 - val_loss: 0.9819 - val_r_square: 0.8536\n",
            "Epoch 9/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1773 - r_square: 0.9938 - val_loss: 0.9813 - val_r_square: 0.8536\n",
            "Epoch 10/150\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.2254 - r_square: 0.9921 - val_loss: 0.9786 - val_r_square: 0.8541\n",
            "Epoch 11/150\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.2129 - r_square: 0.9926 - val_loss: 1.0198 - val_r_square: 0.8479\n",
            "Epoch 12/150\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.1925 - r_square: 0.9933 - val_loss: 0.9948 - val_r_square: 0.8516\n",
            "Epoch 13/150\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.2160 - r_square: 0.9925 - val_loss: 0.9873 - val_r_square: 0.8528\n",
            "Epoch 14/150\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.1674 - r_square: 0.9942 - val_loss: 0.9794 - val_r_square: 0.8539\n",
            "Epoch 15/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1623 - r_square: 0.9943 - val_loss: 1.0207 - val_r_square: 0.8478\n",
            "Epoch 16/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1674 - r_square: 0.9942 - val_loss: 0.9836 - val_r_square: 0.8533\n",
            "Epoch 17/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1516 - r_square: 0.9947 - val_loss: 0.9792 - val_r_square: 0.8540\n",
            "Epoch 18/150\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.1417 - r_square: 0.9951 - val_loss: 0.9783 - val_r_square: 0.8541\n",
            "Epoch 19/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1522 - r_square: 0.9947 - val_loss: 0.9746 - val_r_square: 0.8546\n",
            "Epoch 20/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1511 - r_square: 0.9947 - val_loss: 1.0711 - val_r_square: 0.8403\n",
            "Epoch 21/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1593 - r_square: 0.9944 - val_loss: 0.9800 - val_r_square: 0.8538\n",
            "Epoch 22/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.1922 - r_square: 0.9933 - val_loss: 1.0345 - val_r_square: 0.8457\n",
            "Epoch 23/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.1984 - r_square: 0.9931 - val_loss: 0.9758 - val_r_square: 0.8545\n",
            "Epoch 24/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.1613 - r_square: 0.9944 - val_loss: 1.1018 - val_r_square: 0.8357\n",
            "Epoch 25/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.1804 - r_square: 0.9937 - val_loss: 0.9947 - val_r_square: 0.8517\n",
            "Epoch 26/150\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.1891 - r_square: 0.9934 - val_loss: 0.9859 - val_r_square: 0.8530\n",
            "Epoch 27/150\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.2182 - r_square: 0.9924 - val_loss: 0.9997 - val_r_square: 0.8509\n",
            "Epoch 28/150\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.1650 - r_square: 0.9942 - val_loss: 0.9794 - val_r_square: 0.8539\n",
            "Epoch 29/150\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.1530 - r_square: 0.9947 - val_loss: 1.0058 - val_r_square: 0.8500\n",
            "Epoch 30/150\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.1533 - r_square: 0.9947 - val_loss: 0.9823 - val_r_square: 0.8535\n",
            "Epoch 31/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.1862 - r_square: 0.9935 - val_loss: 1.2637 - val_r_square: 0.8115\n",
            "Epoch 32/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1967 - r_square: 0.9931 - val_loss: 0.9898 - val_r_square: 0.8524\n",
            "Epoch 33/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.2020 - r_square: 0.9930 - val_loss: 1.0000 - val_r_square: 0.8509\n",
            "Epoch 34/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1550 - r_square: 0.9946 - val_loss: 0.9794 - val_r_square: 0.8539\n",
            "Epoch 35/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1715 - r_square: 0.9940 - val_loss: 1.2631 - val_r_square: 0.8116\n",
            "Epoch 36/150\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.1763 - r_square: 0.9939 - val_loss: 0.9920 - val_r_square: 0.8521\n",
            "Epoch 37/150\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.1649 - r_square: 0.9943 - val_loss: 1.0186 - val_r_square: 0.8481\n",
            "Epoch 38/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.1499 - r_square: 0.9948 - val_loss: 1.0253 - val_r_square: 0.8471\n",
            "Epoch 39/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1415 - r_square: 0.9951 - val_loss: 0.9820 - val_r_square: 0.8536\n",
            "Epoch 40/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1764 - r_square: 0.9939 - val_loss: 1.1787 - val_r_square: 0.8242\n",
            "Epoch 41/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.2165 - r_square: 0.9925 - val_loss: 1.2077 - val_r_square: 0.8199\n",
            "Epoch 42/150\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.2259 - r_square: 0.9921 - val_loss: 1.0900 - val_r_square: 0.8374\n",
            "Epoch 43/150\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.1874 - r_square: 0.9935 - val_loss: 0.9983 - val_r_square: 0.8511\n",
            "Epoch 44/150\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.1637 - r_square: 0.9943 - val_loss: 0.9882 - val_r_square: 0.8526\n",
            "Epoch 45/150\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.2590 - r_square: 0.9910 - val_loss: 0.9760 - val_r_square: 0.8544\n",
            "Epoch 46/150\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.1923 - r_square: 0.9933 - val_loss: 1.0757 - val_r_square: 0.8396\n",
            "Epoch 47/150\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.1635 - r_square: 0.9943 - val_loss: 1.0571 - val_r_square: 0.8423\n",
            "Epoch 48/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4751 - r_square: 0.9834 - val_loss: 1.0551 - val_r_square: 0.8426\n",
            "Epoch 49/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.2280 - r_square: 0.9921 - val_loss: 2.0849 - val_r_square: 0.6891\n",
            "Epoch 50/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.2571 - r_square: 0.9910 - val_loss: 0.9869 - val_r_square: 0.8528\n",
            "Epoch 51/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1659 - r_square: 0.9942 - val_loss: 1.0415 - val_r_square: 0.8447\n",
            "Epoch 52/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1821 - r_square: 0.9937 - val_loss: 0.9760 - val_r_square: 0.8544\n",
            "Epoch 53/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1521 - r_square: 0.9947 - val_loss: 1.0124 - val_r_square: 0.8490\n",
            "Epoch 54/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1497 - r_square: 0.9948 - val_loss: 1.0071 - val_r_square: 0.8498\n",
            "Epoch 55/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1393 - r_square: 0.9951 - val_loss: 1.0335 - val_r_square: 0.8459\n",
            "Epoch 56/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1461 - r_square: 0.9949 - val_loss: 1.0052 - val_r_square: 0.8501\n",
            "Epoch 57/150\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.1816 - r_square: 0.9937 - val_loss: 1.0017 - val_r_square: 0.8506\n",
            "Epoch 58/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1597 - r_square: 0.9944 - val_loss: 1.0660 - val_r_square: 0.8410\n",
            "Epoch 59/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1470 - r_square: 0.9949 - val_loss: 0.9777 - val_r_square: 0.8542\n",
            "Epoch 60/150\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.1271 - r_square: 0.9956 - val_loss: 1.2161 - val_r_square: 0.8186\n",
            "Epoch 61/150\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.1630 - r_square: 0.9943 - val_loss: 0.9947 - val_r_square: 0.8517\n",
            "Epoch 62/150\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.1835 - r_square: 0.9936 - val_loss: 0.9902 - val_r_square: 0.8523\n",
            "Epoch 63/150\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.1240 - r_square: 0.9957 - val_loss: 1.2696 - val_r_square: 0.8107\n",
            "Epoch 64/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1778 - r_square: 0.9938 - val_loss: 0.9851 - val_r_square: 0.8531\n",
            "Epoch 65/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.1901 - r_square: 0.9934 - val_loss: 0.9941 - val_r_square: 0.8517\n",
            "Epoch 66/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1383 - r_square: 0.9952 - val_loss: 1.0304 - val_r_square: 0.8463\n",
            "Epoch 67/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1266 - r_square: 0.9956 - val_loss: 0.9788 - val_r_square: 0.8540\n",
            "Epoch 68/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1382 - r_square: 0.9952 - val_loss: 1.0023 - val_r_square: 0.8505\n",
            "Epoch 69/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1223 - r_square: 0.9957 - val_loss: 1.0142 - val_r_square: 0.8487\n",
            "Epoch 70/150\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.1804 - r_square: 0.9937 - val_loss: 1.0169 - val_r_square: 0.8483\n",
            "Epoch 71/150\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.1345 - r_square: 0.9953 - val_loss: 0.9807 - val_r_square: 0.8537\n",
            "Epoch 72/150\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.1533 - r_square: 0.9947 - val_loss: 0.9833 - val_r_square: 0.8533\n",
            "Epoch 73/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1320 - r_square: 0.9954 - val_loss: 0.9932 - val_r_square: 0.8519\n",
            "Epoch 74/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.1442 - r_square: 0.9950 - val_loss: 0.9810 - val_r_square: 0.8537\n",
            "Epoch 75/150\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.1607 - r_square: 0.9944 - val_loss: 0.9940 - val_r_square: 0.8518\n",
            "Epoch 76/150\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.1492 - r_square: 0.9948 - val_loss: 0.9733 - val_r_square: 0.8548\n",
            "Epoch 77/150\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.1389 - r_square: 0.9952 - val_loss: 0.9935 - val_r_square: 0.8518\n",
            "Epoch 78/150\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.1580 - r_square: 0.9945 - val_loss: 0.9774 - val_r_square: 0.8542\n",
            "Epoch 79/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1817 - r_square: 0.9937 - val_loss: 1.0531 - val_r_square: 0.8429\n",
            "Epoch 80/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1645 - r_square: 0.9943 - val_loss: 0.9874 - val_r_square: 0.8527\n",
            "Epoch 81/150\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.1262 - r_square: 0.9956 - val_loss: 0.9969 - val_r_square: 0.8513\n",
            "Epoch 82/150\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.1575 - r_square: 0.9945 - val_loss: 0.9811 - val_r_square: 0.8537\n",
            "Epoch 83/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.1319 - r_square: 0.9954 - val_loss: 1.0003 - val_r_square: 0.8508\n",
            "Epoch 84/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1372 - r_square: 0.9952 - val_loss: 1.4450 - val_r_square: 0.7845\n",
            "Epoch 85/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.5289 - r_square: 0.9816 - val_loss: 0.9709 - val_r_square: 0.8552\n",
            "Epoch 86/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.2275 - r_square: 0.9921 - val_loss: 1.0436 - val_r_square: 0.8444\n",
            "Epoch 87/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1890 - r_square: 0.9934 - val_loss: 1.3905 - val_r_square: 0.7926\n",
            "Epoch 88/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.1965 - r_square: 0.9931 - val_loss: 1.0034 - val_r_square: 0.8504\n",
            "Epoch 89/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.2193 - r_square: 0.9924 - val_loss: 0.9927 - val_r_square: 0.8520\n",
            "Epoch 90/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1390 - r_square: 0.9952 - val_loss: 0.9850 - val_r_square: 0.8531\n",
            "Epoch 91/150\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.1355 - r_square: 0.9953 - val_loss: 0.9786 - val_r_square: 0.8540\n",
            "Epoch 92/150\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.1146 - r_square: 0.9960 - val_loss: 0.9792 - val_r_square: 0.8540\n",
            "Epoch 93/150\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.1260 - r_square: 0.9956 - val_loss: 0.9963 - val_r_square: 0.8514\n",
            "Epoch 94/150\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.1430 - r_square: 0.9950 - val_loss: 3.0505 - val_r_square: 0.5451\n",
            "Epoch 95/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.2473 - r_square: 0.9914 - val_loss: 0.9794 - val_r_square: 0.8539\n",
            "Epoch 96/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.1209 - r_square: 0.9958 - val_loss: 1.0972 - val_r_square: 0.8364\n",
            "Epoch 97/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1295 - r_square: 0.9955 - val_loss: 0.9769 - val_r_square: 0.8543\n",
            "Epoch 98/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1496 - r_square: 0.9948 - val_loss: 1.0192 - val_r_square: 0.8480\n",
            "Epoch 99/150\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.1207 - r_square: 0.9958 - val_loss: 0.9792 - val_r_square: 0.8540\n",
            "Epoch 100/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1325 - r_square: 0.9954 - val_loss: 1.0915 - val_r_square: 0.8372\n",
            "Epoch 101/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1631 - r_square: 0.9943 - val_loss: 0.9843 - val_r_square: 0.8532\n",
            "Epoch 102/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1584 - r_square: 0.9945 - val_loss: 1.0058 - val_r_square: 0.8500\n",
            "Epoch 103/150\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.1466 - r_square: 0.9949 - val_loss: 0.9932 - val_r_square: 0.8519\n",
            "Epoch 104/150\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.1301 - r_square: 0.9955 - val_loss: 1.0064 - val_r_square: 0.8499\n",
            "Epoch 105/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1513 - r_square: 0.9947 - val_loss: 0.9853 - val_r_square: 0.8531\n",
            "Epoch 106/150\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.1367 - r_square: 0.9952 - val_loss: 0.9939 - val_r_square: 0.8518\n",
            "Epoch 107/150\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.1260 - r_square: 0.9956 - val_loss: 0.9943 - val_r_square: 0.8517\n",
            "Epoch 108/150\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.1431 - r_square: 0.9950 - val_loss: 1.0223 - val_r_square: 0.8475\n",
            "Epoch 109/150\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.1337 - r_square: 0.9953 - val_loss: 1.0108 - val_r_square: 0.8493\n",
            "Epoch 110/150\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.1603 - r_square: 0.9944 - val_loss: 1.0882 - val_r_square: 0.8377\n",
            "Epoch 111/150\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.1519 - r_square: 0.9947 - val_loss: 1.1291 - val_r_square: 0.8316\n",
            "Epoch 112/150\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.1266 - r_square: 0.9956 - val_loss: 1.0314 - val_r_square: 0.8462\n",
            "Epoch 113/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1364 - r_square: 0.9952 - val_loss: 1.0135 - val_r_square: 0.8489\n",
            "Epoch 114/150\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.1465 - r_square: 0.9949 - val_loss: 0.9848 - val_r_square: 0.8531\n",
            "Epoch 115/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1418 - r_square: 0.9951 - val_loss: 1.0903 - val_r_square: 0.8374\n",
            "Epoch 116/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.1407 - r_square: 0.9951 - val_loss: 1.0000 - val_r_square: 0.8509\n",
            "Epoch 117/150\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.1159 - r_square: 0.9960 - val_loss: 0.9809 - val_r_square: 0.8537\n",
            "Epoch 118/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.1428 - r_square: 0.9950 - val_loss: 1.1076 - val_r_square: 0.8348\n",
            "Epoch 119/150\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.1313 - r_square: 0.9954 - val_loss: 0.9877 - val_r_square: 0.8527\n",
            "Epoch 120/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1280 - r_square: 0.9955 - val_loss: 1.1872 - val_r_square: 0.8229\n",
            "Epoch 121/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1788 - r_square: 0.9938 - val_loss: 1.0418 - val_r_square: 0.8446\n",
            "Epoch 122/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1538 - r_square: 0.9946 - val_loss: 0.9823 - val_r_square: 0.8535\n",
            "Epoch 123/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1107 - r_square: 0.9961 - val_loss: 28.2578 - val_r_square: -3.2143\n",
            "Epoch 124/150\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 1.9888 - r_square: 0.9307 - val_loss: 0.9738 - val_r_square: 0.8548\n",
            "Epoch 125/150\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.1225 - r_square: 0.9957 - val_loss: 1.0356 - val_r_square: 0.8456\n",
            "Epoch 126/150\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.1287 - r_square: 0.9955 - val_loss: 0.9746 - val_r_square: 0.8546\n",
            "Epoch 127/150\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.1182 - r_square: 0.9959 - val_loss: 0.9956 - val_r_square: 0.8515\n",
            "Epoch 128/150\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.1286 - r_square: 0.9955 - val_loss: 0.9801 - val_r_square: 0.8538\n",
            "Epoch 129/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1256 - r_square: 0.9956 - val_loss: 0.9871 - val_r_square: 0.8528\n",
            "Epoch 130/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1213 - r_square: 0.9958 - val_loss: 0.9830 - val_r_square: 0.8534\n",
            "Epoch 131/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1185 - r_square: 0.9959 - val_loss: 1.0315 - val_r_square: 0.8462\n",
            "Epoch 132/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1541 - r_square: 0.9946 - val_loss: 0.9775 - val_r_square: 0.8542\n",
            "Epoch 133/150\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.1228 - r_square: 0.9957 - val_loss: 0.9783 - val_r_square: 0.8541\n",
            "Epoch 134/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1261 - r_square: 0.9956 - val_loss: 0.9868 - val_r_square: 0.8528\n",
            "Epoch 135/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1424 - r_square: 0.9950 - val_loss: 0.9742 - val_r_square: 0.8547\n",
            "Epoch 136/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1208 - r_square: 0.9958 - val_loss: 0.9752 - val_r_square: 0.8546\n",
            "Epoch 137/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1368 - r_square: 0.9952 - val_loss: 1.0350 - val_r_square: 0.8456\n",
            "Epoch 138/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1289 - r_square: 0.9955 - val_loss: 0.9801 - val_r_square: 0.8538\n",
            "Epoch 139/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1118 - r_square: 0.9961 - val_loss: 1.1194 - val_r_square: 0.8331\n",
            "Epoch 140/150\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.1559 - r_square: 0.9946 - val_loss: 0.9854 - val_r_square: 0.8530\n",
            "Epoch 141/150\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.1242 - r_square: 0.9957 - val_loss: 0.9795 - val_r_square: 0.8539\n",
            "Epoch 142/150\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.1236 - r_square: 0.9957 - val_loss: 0.9809 - val_r_square: 0.8537\n",
            "Epoch 143/150\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.1228 - r_square: 0.9957 - val_loss: 0.9817 - val_r_square: 0.8536\n",
            "Epoch 144/150\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.1195 - r_square: 0.9958 - val_loss: 0.9887 - val_r_square: 0.8525\n",
            "Epoch 145/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1126 - r_square: 0.9961 - val_loss: 1.4492 - val_r_square: 0.7839\n",
            "Epoch 146/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1783 - r_square: 0.9938 - val_loss: 0.9906 - val_r_square: 0.8523\n",
            "Epoch 147/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1311 - r_square: 0.9954 - val_loss: 0.9844 - val_r_square: 0.8532\n",
            "Epoch 148/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1086 - r_square: 0.9962 - val_loss: 0.9893 - val_r_square: 0.8525\n",
            "Epoch 149/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1132 - r_square: 0.9961 - val_loss: 0.9783 - val_r_square: 0.8541\n",
            "Epoch 150/150\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.1329 - r_square: 0.9954 - val_loss: 0.9852 - val_r_square: 0.8531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/content/my_best_model.hdf5\")"
      ],
      "metadata": {
        "id": "pYj36uKHSWia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1fd124b-f451-417f-e546-aa5d73257b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "model1= keras.models.load_model(\"/content/content/my_best_model.hdf5\")\n"
      ],
      "metadata": {
        "id": "lY9oHcCewLta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of battery files\n",
        "a = glob.glob(\"*.xlsx\")\n",
        "\n",
        "# Loop through each battery file\n",
        "for m in a:\n",
        "    # Load the battery data\n",
        "    df10 = pd.read_excel(m)\n",
        "    df101 = df10.drop(columns=['label', 'cycle number', 'Unnamed: 0', \"Capacity/mA.h\"])\n",
        "\n",
        "    # Initialize with the first 'sequence_length' capacity values for prediction\n",
        "    true_capacity = list(df10[\"Capacity/mA.h\"])  # True capacity values for R-squared calculation\n",
        "    predicted_capacity = true_capacity[:sequence_length]  # First 'sequence_length' true values to start the prediction\n",
        "\n",
        "    # Iterating through the battery data for predictions with adjustable sequence length\n",
        "    for i in range(len(df101) - (sequence_length - 1)):\n",
        "        # Create a sequence of 'sequence_length' steps (the model expects input of shape (sequence_length, 121))\n",
        "        seq = [list(df101.iloc[i + n]) for n in range(sequence_length)]\n",
        "\n",
        "        # Insert the true capacity values into the sequence at the appropriate places\n",
        "        for n in range(sequence_length):\n",
        "            seq[n].insert(0, predicted_capacity[i + n])  # Insert the corresponding capacity value\n",
        "\n",
        "        # Convert the sequence into a numpy array and reshape it to (1, sequence_length, 121)\n",
        "        seq = np.array(seq).reshape(1, sequence_length, 121)\n",
        "\n",
        "        # Make the prediction using the Liquid Neural Network model\n",
        "        predict = model1(tf.convert_to_tensor(seq, dtype=tf.float32))\n",
        "\n",
        "        # Append the predicted capacity value\n",
        "        predicted_capacity.append(predict.numpy()[0][0])\n",
        "\n",
        "    # Since predicted_capacity has extra initial values, slice it to match true_capacity length\n",
        "    predicted_capacity = predicted_capacity[:len(true_capacity)]\n",
        "\n",
        "    # Compute R-squared value for the predictions\n",
        "    r_squared = r2_score(true_capacity, predicted_capacity)\n",
        "    print(f\"R-squared for {m.split('.')[0]}: {r_squared}\")\n",
        "\n",
        "    # Save the predicted results for this battery\n",
        "    results = pd.DataFrame({'True Capacity': true_capacity, 'Predicted Capacity': predicted_capacity})\n",
        "    with pd.ExcelWriter(\"/content/content/\" + m.split('.')[0] + \"_results_with_prediction.xlsx\") as writer:\n",
        "        results.to_excel(writer, index=False)\n",
        "\n",
        "    # Plot the true and predicted capacity values for this battery\n",
        "    plt.figure()  # Create a new figure for each battery\n",
        "    plt.plot(true_capacity, label='True Capacity', color='blue')\n",
        "    plt.plot(predicted_capacity, label='Predicted Capacity', color='red')\n",
        "    plt.title(f\"True vs Predicted Capacity over Cycles for {m.split('.')[0]}\")\n",
        "    plt.xlabel(\"Cycle Number\")\n",
        "    plt.ylabel(\"Capacity (mA.h)\")\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"{m.split('.')[0]}_Capacity_True_vs_Predicted.png\")  # Save the plot as a PNG file\n",
        "    plt.close()  # Close the plot to avoid overlap with the next one\n",
        "\n"
      ],
      "metadata": {
        "id": "BrBEYPPxSqXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f090fb-c39d-43da-92df-cbc91fde8283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared for 25C03: 0.9220701494344158\n",
            "R-squared for 45C01: 0.9181573912539158\n",
            "R-squared for 25C01: 0.8116213442188918\n",
            "R-squared for 25C04: 0.8846314622250739\n",
            "R-squared for 25C07: 0.6259620391553309\n",
            "R-squared for 35C01: 0.38693299341134924\n",
            "R-squared for 25C05: 0.7871019924623952\n",
            "R-squared for 25C02: -2.249969310740224\n",
            "R-squared for 25C08: 0.5060268132785087\n",
            "R-squared for 25C06: -3.0258410357614487\n",
            "R-squared for 35C02: 0.5162240518573302\n",
            "R-squared for 45C02: 0.8385637939240064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iVZL4LUJxrlQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}